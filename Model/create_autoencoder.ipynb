{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Activation, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if start_time is not None:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "    else:\n",
    "        start_time = datetime.now()\n",
    "        return start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "path = Path(os.getenv('PATH_DATASET2')).joinpath('publictracks_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_names = np.genfromtxt(path.joinpath('track_names.csv'), delimiter=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number fo tracks:  17760\n"
     ]
    }
   ],
   "source": [
    "tot_num = len(track_names)\n",
    "print('Total number fo tracks: ', tot_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_paths = []\n",
    "for f in path.iterdir():\n",
    "    f_paths.append(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_paths.remove(f_paths[3722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv files and create a list of data arrays\n",
    "data= []\n",
    "tr_name = []\n",
    "for f in f_paths:\n",
    "    data.append(np.genfromtxt(f, delimiter=','))\n",
    "    tr_name.append(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks: 17651\n",
      "Length of sample input array: 1200\n",
      "Number of tracks match\n",
      "Sample track name: &Run-Sir.csv\n"
     ]
    }
   ],
   "source": [
    "print('Number of tracks:',len(data))\n",
    "print('Length of sample input array:', len(data[0]))\n",
    "if len(tr_name) == len(data) : print('Number of track name and track arrays match')  \n",
    "else: print(\"Number of tracks don't match\")\n",
    "print('Sample track name:', tr_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, tr_name_train, tr_name_test = train_test_split(data, tr_name, test_size = 0.25, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast lists to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[-2000:]\n",
    "tr_name_val = tr_name_train[-2000:]\n",
    "x_train = x_train[:-2000]\n",
    "tr_name_train = tr_name_train[:-2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks in training: 9238\n",
      "Number of tracks in validation: 2000\n",
      "Number of tracks in testing: 4413\n"
     ]
    }
   ],
   "source": [
    "print('Number of tracks in training:', len(x_train))\n",
    "print('Number of tracks in validation:',len(x_val))\n",
    "print('Number of tracks in testing:',len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_functional(inputlength, latent_dim, layer_nodes, activations=None, dropout=False):\n",
    "\n",
    "    def encdec_layer(x, nodes, activation='relu', bn=True, dropout=dropout):\n",
    "    \n",
    "        # define a encoding/decoding layer\n",
    "        \n",
    "        x = Dense(nodes)(x)\n",
    "        x = Activation(activation)(x)\n",
    "        if bn:\n",
    "            x = BatchNormalization()(x)\n",
    "        if dropout:\n",
    "            x = Dropout(0.25)(x)\n",
    "        \n",
    "        return x    \n",
    "    \n",
    "    # DEFAULT ACTIVATIONS\n",
    "    acts = ['relu'] * len(layer_nodes)\n",
    "    \n",
    "    if activations:\n",
    "        if len(activations) == len(layer_nodes):\n",
    "            acts = activations\n",
    "        else:\n",
    "            print(\"Number of activations must be equal to number of layers\")\n",
    "    \n",
    "    # ASSEMBLING ENCODER MODEL\n",
    "    enc_inputs = Input(shape=(inputlength,))\n",
    "    x = encdec_layer(enc_inputs, layer_nodes[0], activation=acts[0])\n",
    "    \n",
    "    # add encoding layers for remainder of depth\n",
    "    for layer_ in range(1, len(layer_nodes)):\n",
    "        x = encdec_layer(x, layer_nodes[layer_], activation=acts[layer_])\n",
    "    \n",
    "    # Last encoding layer with number of nodes = dimension of latent feature space\n",
    "    enc_latent = encdec_layer(x, latent_dim, activation='tanh', dropout=True)\n",
    "    \n",
    "    # ASSEMBLING DECODER MODEL\n",
    "    # Decoder model will be a mirror of the encoder model\n",
    "    # Hence, we will be moving backwards through layer_nodes\n",
    "    \n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = encdec_layer(latent_inputs, layer_nodes[-1], activation=acts[-1])\n",
    "    \n",
    "    # add decoding layers for remainder of depth\n",
    "    for layer_ in reversed(range(1, len(layer_nodes))):\n",
    "        x = encdec_layer(x, layer_nodes[layer_], activation=acts[layer_])\n",
    "    \n",
    "    # Last decoding layer with number of nodes = original input dimension\n",
    "    dec_outputs = encdec_layer(x, inputlength, activation='tanh', dropout=True)\n",
    "    \n",
    "    # Create encoder and decoder model\n",
    "    encoder = Model(inputs=enc_inputs, outputs=enc_latent, name='encoder')\n",
    "    decoder = Model(inputs=latent_inputs, outputs=dec_outputs, name = 'decoder')\n",
    "    # Create autoencoder model\n",
    "    autoencoder = Model(inputs=enc_inputs, outputs=decoder(encoder(enc_inputs)), name = 'autoencoder')\n",
    "    \n",
    "    return (autoencoder, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputlength = len(x_train[0])\n",
    "latent_dim = 50\n",
    "layer_nodes = [400, 200, 100]\n",
    "activations = ['relu', 'relu', 'tanh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input length: 1200\n",
      "\n",
      "Number of layers in encoder/decoder: 4\n",
      "Number of layers in autoencoder: 8\n",
      "\n",
      "NOTE: Each encoding/decoding layer consists of a dense layer, activation layer \n",
      "      and may or may not have a batchnorm layer or a dropout layer.\n",
      "\n",
      "Layer 0 has 400 nodes with activation - relu.\n",
      "Layer 1 has 200 nodes with activation - relu.\n",
      "Layer 2 has 100 nodes with activation - tanh.\n",
      "Layer 3 has  50 nodes with activation - tanh.\n",
      "\n",
      "The last layer in the encoder gives us a reduced dimensional feature space.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('input length:', inputlength)\n",
    "print('\\nNumber of layers in encoder/decoder:', len(layer_nodes)+1)\n",
    "print('Number of layers in autoencoder:', 2*(len(layer_nodes) + 1))\n",
    "print('\\nNOTE: Each encoding/decoding layer consists of a dense layer, activation layer \\\n",
    "\\n      and may or may not have a batchnorm layer or a dropout layer.\\n')\n",
    "      \n",
    "for i in range(len(layer_nodes)):\n",
    "    print('Layer {} has {} nodes with activation - {}.'.format(i, layer_nodes[i], activations[i]))\n",
    "print('Layer {} has  {} nodes with activation - tanh.'.format(len(layer_nodes), latent_dim))\n",
    "print('\\nThe last layer in the encoder gives us a reduced dimensional feature space.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "autoencoder, encoder, decoder = autoencoder_functional(inputlength, latent_dim =latent_dim, \\\n",
    "                                            layer_nodes=layer_nodes, activations=activations, dropout=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.07347737,  0.0329092 ,  0.05429836, ...,  0.17816927,\n",
       "          0.00850554,  0.01360936],\n",
       "        [ 0.09909363,  0.06306238, -0.14623761, ...,  0.09917618,\n",
       "         -0.11254063, -0.1408535 ],\n",
       "        [-0.00163308, -0.17235552,  0.11359926, ..., -0.19663297,\n",
       "         -0.19500351,  0.13404955],\n",
       "        ...,\n",
       "        [ 0.19081388,  0.14369269,  0.04819909, ...,  0.03154078,\n",
       "         -0.11043105, -0.12191267],\n",
       "        [ 0.10830842,  0.03466821, -0.05534701, ...,  0.05124713,\n",
       "          0.00607271,  0.00878949],\n",
       "        [-0.18584453, -0.05887942,  0.10120259, ...,  0.02133155,\n",
       "         -0.06625824, -0.18255568]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.get_layer('dense_3').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.07347737,  0.0329092 ,  0.05429836, ...,  0.17816927,\n",
       "          0.00850554,  0.01360936],\n",
       "        [ 0.09909363,  0.06306238, -0.14623761, ...,  0.09917618,\n",
       "         -0.11254063, -0.1408535 ],\n",
       "        [-0.00163308, -0.17235552,  0.11359926, ..., -0.19663297,\n",
       "         -0.19500351,  0.13404955],\n",
       "        ...,\n",
       "        [ 0.19081388,  0.14369269,  0.04819909, ...,  0.03154078,\n",
       "         -0.11043105, -0.12191267],\n",
       "        [ 0.10830842,  0.03466821, -0.05534701, ...,  0.05124713,\n",
       "          0.00607271,  0.00878949],\n",
       "        [-0.18584453, -0.05887942,  0.10120259, ...,  0.02133155,\n",
       "         -0.06625824, -0.18255568]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.get_layer('encoder').get_layer('dense_3').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_STEPS_PER_EPOCH = np.ceil(len(x_train)/ BATCH_SIZE)       #np.ceil(TRAIN_COUNT/BATCH_SIZE)\n",
    "VAL_STEPS_PER_EPOCH = np.ceil(len(x_val)/BATCH_SIZE)        #np.ceil(VAL_COUNT/BATCH_SIZE)\n",
    "TEST_STEPS = len(x_test)\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "145/145 [==============================] - 254s 2s/step - loss: 1.1593 - mean_squared_error: 1.1593 - val_loss: 0.4720 - val_mean_squared_error: 0.4720\n",
      "Epoch 2/5\n",
      "145/145 [==============================] - 262s 2s/step - loss: 0.8110 - mean_squared_error: 0.8110 - val_loss: 0.3013 - val_mean_squared_error: 0.3013\n",
      "Epoch 3/5\n",
      "145/145 [==============================] - 270s 2s/step - loss: 0.4366 - mean_squared_error: 0.4366 - val_loss: 0.4719 - val_mean_squared_error: 0.4719\n",
      "Epoch 4/5\n",
      "145/145 [==============================] - 275s 2s/step - loss: 0.0745 - mean_squared_error: 0.0745 - val_loss: 0.1737 - val_mean_squared_error: 0.1737\n",
      "Epoch 5/5\n",
      "145/145 [==============================] - 274s 2s/step - loss: 0.0707 - mean_squared_error: 0.0707 - val_loss: 0.0862 - val_mean_squared_error: 0.0862\n",
      "\n",
      " Time taken: 0 hours 22 minutes and 16.9 seconds.\n"
     ]
    }
   ],
   "source": [
    "st_time = timer(None)\n",
    "autoenc = autoencoder.fit(x=x_train, y=x_train,\n",
    "                          steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n",
    "                          epochs = EPOCHS, shuffle=False,\n",
    "                          validation_data = (x_val, x_val),\n",
    "                          validation_steps= VAL_STEPS_PER_EPOCH)\n",
    "timer(st_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.07741034,  0.01946484,  0.02221563, ...,  0.11088157,\n",
       "          0.06397545,  0.0207343 ],\n",
       "        [ 0.05684531,  0.04776891, -0.11114325, ...,  0.08102795,\n",
       "         -0.0382463 , -0.06827035],\n",
       "        [-0.01745828, -0.08250307,  0.156531  , ..., -0.09705876,\n",
       "         -0.1688261 ,  0.08050036],\n",
       "        ...,\n",
       "        [ 0.09508882,  0.11078127,  0.13488206, ...,  0.00396039,\n",
       "         -0.16677007, -0.10692524],\n",
       "        [ 0.06418883,  0.09210512, -0.0302702 , ...,  0.00326248,\n",
       "          0.00720771,  0.02971781],\n",
       "        [-0.12228182, -0.06985266,  0.0567733 , ...,  0.03428658,\n",
       "         -0.04222217, -0.15125948]], dtype=float32),\n",
       " array([ 2.23267847e-03, -3.21475975e-02,  3.40749994e-02, -3.61994021e-02,\n",
       "         1.69316394e-04,  1.67661294e-01, -5.06708864e-03, -1.29663473e-04,\n",
       "         2.83424999e-03, -8.54090899e-02, -2.02340297e-02,  2.80528180e-02,\n",
       "        -7.25839380e-03, -2.03876430e-03, -7.06078298e-03, -9.26623344e-02,\n",
       "        -8.32440928e-02, -8.09156373e-02, -6.58074319e-02, -5.49659841e-02,\n",
       "         4.72321808e-02,  7.42803812e-02,  3.79079059e-02,  5.77906482e-02,\n",
       "        -1.43909417e-02,  6.09242693e-02, -4.39216569e-02, -4.93407249e-02,\n",
       "         5.31795174e-02, -1.27308652e-01,  1.05271213e-01,  9.51024666e-02,\n",
       "        -5.34499884e-02, -1.39123306e-01, -1.12734914e-01, -6.56739846e-02,\n",
       "        -9.17713717e-02, -2.00586170e-02, -2.52284538e-02,  1.78982183e-01,\n",
       "        -2.87638512e-02,  1.69991199e-02, -1.10293351e-01,  7.75816515e-02,\n",
       "         1.72758430e-01, -4.22675870e-02, -9.20917243e-02,  4.00884300e-02,\n",
       "        -4.28242050e-03, -6.27286136e-02], dtype=float32)]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.get_layer('encoder').get_layer('dense_3').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.2110815 , -1.0433093 , -1.2517    ,  0.47041315, -0.7390007 ,\n",
       "         0.6040875 , -1.1193643 ,  0.7933613 , -0.45897102, -0.9392003 ,\n",
       "         1.1238505 ,  1.0214757 , -0.90243196, -1.0413766 , -1.1636659 ,\n",
       "        -1.1826581 , -1.1321986 , -1.1559083 , -0.24298921, -1.2482964 ,\n",
       "         0.21138465,  0.26654953, -1.1740204 , -0.6471349 ,  0.81743467,\n",
       "        -1.2306262 , -0.41867378, -1.1011943 , -0.61266196, -0.9025874 ,\n",
       "         0.58824086,  1.0680349 , -0.72454953,  0.528056  ,  0.88737035,\n",
       "         0.5664663 , -0.41335368,  0.18181613,  0.34764242,  0.9378705 ,\n",
       "        -1.0176069 ,  0.45071644,  1.3431733 ,  1.200258  ,  1.1496104 ,\n",
       "        -0.9614325 , -0.02830141,  0.80525696,  0.8734684 , -0.94281787]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_out = encoder.predict(np.array([x_test[0]]))\n",
    "encoded_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(filepath=Path(os.getenv('PATH_DATASET2')).joinpath('autoencoder'))\n",
    "encoder.save(filepath=Path(os.getenv('PATH_DATASET2')).joinpath('encoder'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model(filepath=Path(os.getenv('PATH_MODELS')).joinpath('encoder'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "#import graphviz\n",
    "#import pydot\n",
    "#keras.utils.plot_model(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
